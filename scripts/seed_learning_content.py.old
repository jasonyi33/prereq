"""
Seed precomputed learning pages and quiz questions for concepts.
Run this after the main seed script has created concepts.
"""
import os
import sys
from dotenv import load_dotenv
from supabase import create_client

# Load environment variables
load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("ERROR: SUPABASE_URL and SUPABASE_KEY must be set in .env")
    sys.exit(1)

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# Learning content by concept label (must match database labels exactly)
LEARNING_CONTENT = {
    "backpropagation": """# Understanding Backpropagation

## What is Backpropagation?

Backpropagation is the fundamental algorithm for training neural networks. It efficiently computes gradients of the loss function with respect to all network weights by applying the chain rule backwards through the network.

## Key Concepts

**Forward Pass**: Data flows through the network, computing activations at each layer until producing a prediction.

**Loss Calculation**: The difference between prediction and target is quantified using a loss function (e.g., MSE for regression, cross-entropy for classification).

**Backward Pass**: Starting from the loss, gradients are computed layer-by-layer in reverse order. Each layer computes:
- Gradient with respect to its inputs
- Gradient with respect to its weights

## The Chain Rule in Action

For a simple network: $x \\rightarrow h \\rightarrow y$

$$\\frac{\\partial L}{\\partial w_1} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial h} \\cdot \\frac{\\partial h}{\\partial w_1}$$

## Why It Matters

- **Efficiency**: Computes all gradients in one backward pass (O(n) instead of O(n²))
- **Foundation**: Enables training of deep networks with millions of parameters
- **Automatic**: Modern frameworks (PyTorch, TensorFlow) implement this automatically

## Common Pitfalls

- Vanishing gradients in deep networks (solved by ReLU, batch normalization)
- Exploding gradients (solved by gradient clipping)
- Forgetting to zero gradients between batches
""",

    "gradient_descent": """# Gradient Descent Optimization

## Core Idea

Gradient descent minimizes a function by iteratively moving in the direction of steepest descent (negative gradient).

## Update Rule

$$w_{t+1} = w_t - \\eta \\nabla L(w_t)$$

Where:
- $w_t$ = current weights
- $\\eta$ = learning rate
- $\\nabla L(w_t)$ = gradient of loss function

## Variants

### Batch Gradient Descent
- Computes gradient over entire dataset
- **Pros**: Stable convergence
- **Cons**: Slow for large datasets

### Stochastic Gradient Descent (SGD)
- Updates after each training example
- **Pros**: Fast, can escape local minima
- **Cons**: Noisy updates

### Mini-batch Gradient Descent
- Compromise between batch and SGD
- **Standard choice**: Batch sizes of 32-256

## Learning Rate

The learning rate $\\eta$ is critical:
- **Too high**: Oscillation, divergence
- **Too low**: Slow convergence
- **Solution**: Learning rate schedules, adaptive methods (Adam, RMSprop)

## Convergence

Gradient descent converges when:
- $\\|\\nabla L(w)\\| < \\epsilon$ (gradient magnitude is small)
- Loss stops decreasing significantly
""",

    "regularization": """# Dropout Regularization

## The Problem: Overfitting

Neural networks can memorize training data instead of learning generalizable patterns. This leads to poor performance on new data.

## How Dropout Works

During training, randomly "drop out" (set to zero) a fraction of neurons in each layer with probability $p$ (typically 0.2-0.5).

### Training Phase
- Each forward pass uses a different random subset of neurons
- Forces network to learn robust features that work with different neuron combinations
- Prevents co-adaptation of neurons

### Test Phase
- Use ALL neurons (no dropout)
- Scale activations by $(1-p)$ to maintain expected output magnitude
- Modern frameworks handle this automatically

## Mathematical View

Dropout approximates training an ensemble of $2^n$ different networks (where $n$ = number of neurons).

## Best Practices

- **Typical values**: 0.5 for hidden layers, 0.2 for input layer
- **Don't use on output layer**
- **Combine with other regularization**: L2 regularization, batch normalization
- **Less effective with batch normalization**: BN provides its own regularization

## When to Use

- Large networks prone to overfitting
- Limited training data
- High capacity models
""",
}

# Quiz questions by concept label (must match database labels exactly)
QUIZ_QUESTIONS = {
    "backpropagation": [
        {
            "question": "What is the primary purpose of backpropagation in neural networks?",
            "option_a": "To compute the output of the network",
            "option_b": "To efficiently compute gradients for all weights",
            "option_c": "To initialize the network weights",
            "option_d": "To prevent overfitting during training",
            "correct_answer": 1,
            "explanation": "Backpropagation efficiently computes gradients of the loss with respect to all weights by applying the chain rule backwards through the network. This is what enables gradient-based optimization of neural networks."
        },
        {
            "question": "In what order are gradients computed during backpropagation?",
            "option_a": "From input layer to output layer",
            "option_b": "From output layer to input layer",
            "option_c": "Randomly across all layers",
            "option_d": "Simultaneously for all layers",
            "correct_answer": 1,
            "explanation": "Backpropagation computes gradients from output layer to input layer (backwards through the network), using the chain rule to propagate error signals."
        },
        {
            "question": "What is the vanishing gradient problem?",
            "option_a": "Gradients become zero during forward propagation",
            "option_b": "Gradients become very small in early layers of deep networks",
            "option_c": "Gradients grow exponentially during training",
            "option_d": "Gradients oscillate between positive and negative values",
            "correct_answer": 1,
            "explanation": "In deep networks, gradients can become very small as they're propagated backwards through many layers, making it difficult to train early layers effectively. This is especially problematic with sigmoid/tanh activations."
        },
        {
            "question": "Which mathematical concept is fundamental to backpropagation?",
            "option_a": "Integration by parts",
            "option_b": "The chain rule of calculus",
            "option_c": "Taylor series expansion",
            "option_d": "Fourier transforms",
            "correct_answer": 1,
            "explanation": "The chain rule allows us to decompose the gradient of a composite function into products of simpler gradients, which is exactly what backpropagation does as it moves backwards through the network layers."
        },
        {
            "question": "What should you do with gradients between training batches?",
            "option_a": "Accumulate them across batches",
            "option_b": "Average them with previous batches",
            "option_c": "Zero them out before computing new gradients",
            "option_d": "Multiply them by the learning rate",
            "correct_answer": 2,
            "explanation": "Gradients must be zeroed out between batches because PyTorch/TensorFlow accumulate gradients by default. Forgetting to zero gradients leads to incorrect gradient values."
        }
    ],

    "gradient_descent": [
        {
            "question": "What does the learning rate (η) control in gradient descent?",
            "option_a": "The batch size for each update",
            "option_b": "The step size in the direction of the negative gradient",
            "option_c": "The number of training epochs",
            "option_d": "The depth of the neural network",
            "correct_answer": 1,
            "explanation": "The learning rate controls how large a step we take in the direction of the negative gradient. It's a crucial hyperparameter that affects convergence speed and stability."
        },
        {
            "question": "What happens if the learning rate is too high?",
            "option_a": "Training converges very slowly",
            "option_b": "The model underfits the training data",
            "option_c": "Updates may oscillate or diverge",
            "option_d": "The network becomes too deep",
            "correct_answer": 2,
            "explanation": "A learning rate that's too high causes the optimizer to take steps that are too large, potentially overshooting the minimum and causing oscillation or divergence."
        },
        {
            "question": "What is the main advantage of mini-batch gradient descent over batch gradient descent?",
            "option_a": "It always finds the global minimum",
            "option_b": "It's faster per update and adds beneficial noise",
            "option_c": "It requires less memory than SGD",
            "option_d": "It eliminates the need for a learning rate",
            "correct_answer": 1,
            "explanation": "Mini-batch gradient descent processes smaller subsets of data per update, making it faster than full-batch gradient descent while still providing more stable gradients than single-example SGD. The noise can also help escape local minima."
        },
        {
            "question": "In the update rule w_new = w_old - η∇L(w), what does ∇L(w) represent?",
            "option_a": "The loss function value",
            "option_b": "The gradient (direction of steepest ascent) of the loss",
            "option_c": "The learning rate schedule",
            "option_d": "The weight initialization",
            "correct_answer": 1,
            "explanation": "∇L(w) is the gradient of the loss function with respect to weights, pointing in the direction of steepest ascent. We move in the negative direction (steepest descent) to minimize loss."
        },
        {
            "question": "What indicates that gradient descent has converged?",
            "option_a": "The loss reaches exactly zero",
            "option_b": "The gradient magnitude becomes very small",
            "option_c": "The learning rate becomes zero",
            "option_d": "All weights become equal",
            "correct_answer": 1,
            "explanation": "Convergence is indicated when the gradient magnitude ‖∇L(w)‖ becomes very small, meaning we're near a local minimum where the loss surface is relatively flat."
        }
    ],

    "regularization": [
        {
            "question": "What is the primary purpose of dropout?",
            "option_a": "To speed up training",
            "option_b": "To reduce overfitting by preventing co-adaptation of neurons",
            "option_c": "To increase the number of parameters",
            "option_d": "To replace batch normalization",
            "correct_answer": 1,
            "explanation": "Dropout prevents overfitting by randomly dropping neurons during training, which prevents neurons from co-adapting too much to specific training examples and forces the network to learn more robust features."
        },
        {
            "question": "During the test/inference phase, how is dropout applied?",
            "option_a": "Neurons are still randomly dropped with probability p",
            "option_b": "All neurons are used without any dropout",
            "option_c": "Only 50% of neurons are used",
            "option_d": "Dropout is applied to the input layer only",
            "correct_answer": 1,
            "explanation": "During testing, dropout is turned off and all neurons are used. This is because we want the full network capacity for making predictions, not a random subset."
        },
        {
            "question": "What is a typical dropout probability (p) for hidden layers?",
            "option_a": "0.1 (10%)",
            "option_b": "0.5 (50%)",
            "option_c": "0.8 (80%)",
            "option_d": "0.95 (95%)",
            "correct_answer": 1,
            "explanation": "A dropout probability of 0.5 is most common for hidden layers, meaning 50% of neurons are dropped during each training pass. Input layers typically use lower values like 0.2."
        },
        {
            "question": "How can dropout be interpreted mathematically?",
            "option_a": "As gradient clipping",
            "option_b": "As training an ensemble of many different networks",
            "option_c": "As L1 regularization",
            "option_d": "As momentum optimization",
            "correct_answer": 1,
            "explanation": "Dropout can be viewed as training an ensemble of 2^n different networks (where n is the number of neurons), as each training pass uses a different random subset of the network."
        },
        {
            "question": "Should dropout be applied to the output layer?",
            "option_a": "Yes, always",
            "option_b": "No, typically not",
            "option_c": "Only for classification tasks",
            "option_d": "Only for regression tasks",
            "correct_answer": 1,
            "explanation": "Dropout is not typically applied to the output layer because we need all output neurons to produce predictions. Dropout is used on hidden layers to prevent overfitting."
        }
    ]
}

def main():
    print("Fetching concepts from database...")

    # Get all concept nodes
    result = supabase.table('concept_nodes').select('id, label').execute()
    concepts = {c['label']: c['id'] for c in result.data}

    print(f"Found {len(concepts)} concepts in database")
    print(f"Available labels: {list(concepts.keys())[:10]}...")  # Show first 10

    # Insert learning pages
    print("\nInserting learning pages...")
    for label, content in LEARNING_CONTENT.items():
        if label not in concepts:
            print(f"  ⚠️  Concept '{label}' not found in database, skipping")
            continue

        concept_id = concepts[label]

        # Check if already exists
        existing = supabase.table('concept_learning_pages').select('id').eq('concept_id', concept_id).execute()
        if existing.data:
            print(f"  ⏭️  Learning page for '{label}' already exists, skipping")
            continue

        # Insert new learning page
        supabase.table('concept_learning_pages').insert({
            'concept_id': concept_id,
            'content': content
        }).execute()
        print(f"  ✅ Inserted learning page for '{label}'")

    # Insert quiz questions
    print("\nInserting quiz questions...")
    for label, questions in QUIZ_QUESTIONS.items():
        if label not in concepts:
            print(f"  ⚠️  Concept '{label}' not found in database, skipping")
            continue

        concept_id = concepts[label]

        # Check if already exists
        existing = supabase.table('concept_quiz_questions').select('id').eq('concept_id', concept_id).execute()
        if existing.data:
            print(f"  ⏭️  Quiz questions for '{label}' already exist, skipping")
            continue

        # Insert all questions for this concept
        for idx, q in enumerate(questions):
            supabase.table('concept_quiz_questions').insert({
                'concept_id': concept_id,
                'question': q['question'],
                'option_a': q['option_a'],
                'option_b': q['option_b'],
                'option_c': q['option_c'],
                'option_d': q['option_d'],
                'correct_answer': q['correct_answer'],
                'explanation': q['explanation'],
                'question_order': idx
            }).execute()

        print(f"  ✅ Inserted {len(questions)} quiz questions for '{label}'")

    print("\n✨ Seed complete!")

if __name__ == '__main__':
    main()